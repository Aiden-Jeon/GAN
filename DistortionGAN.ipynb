{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg19(nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(Vgg19, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        \n",
    "        for x in range(4):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(4, 32):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.slice1(x)\n",
    "        h_relu_1_2 = h\n",
    "        h = self.slice2(h)\n",
    "        h_relu_5_2 = h\n",
    "        vgg_outputs = namedtuple(\"VggOutputs\", ['relu_1_2', 'relu_5_2'])\n",
    "        out = vgg_outputs(h_relu_1_2, h_relu_5_2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvUp(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, kernel_size, stride, padding, batch_norm, dtype):\n",
    "        super(ConvUp, self).__init__()\n",
    "        features = [nn.Conv2d(input_nc, output_nc, kernel_size, stride, padding)]\n",
    "        if batch_norm:\n",
    "            features += [nn.BatchNorm2d(output_nc)]\n",
    "        features += [nn.LeakyReLU(0.2, True)]\n",
    "        self.features = nn.Sequential(*features).type(dtype)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "\n",
    "class DeconvDown(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, kernel_size, stride, padding, batch_norm, dropout, dtype):\n",
    "        super(DeconvDown, self).__init__()\n",
    "        features = [nn.ConvTranspose2d(input_nc, output_nc, kernel_size, stride, padding)]\n",
    "        if batch_norm:\n",
    "            features += [nn.BatchNorm2d(output_nc)]\n",
    "        if dropout:\n",
    "            features += [nn.Dropout2d(0.5)]\n",
    "        features += [nn.LeakyReLU(0.2, True)]\n",
    "        self.features = nn.Sequential(*features).type(dtype)\n",
    "\n",
    "    def forward(self, x, eo):\n",
    "        x = torch.cat([x, eo], 1)\n",
    "        return self.features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, dtype):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.e1 = ConvUp(3, 64, 4, 2, 1, True, dtype)\n",
    "        self.e2 = ConvUp(64, 128, 4, 2, 1, True, dtype)\n",
    "        self.e3 = ConvUp(128, 256, 4, 2, 1, True, dtype)\n",
    "        self.e4 = ConvUp(256, 512, 4, 2, 1, True, dtype)\n",
    "        self.e5 = ConvUp(512, 512, 4, 2, 1, True, dtype)\n",
    "        self.e6 = ConvUp(512, 512, 4, 2, 1, True, dtype)\n",
    "        self.e7 = ConvUp(512, 512, 4, 2, 1, True, dtype)\n",
    "        self.e8 = ConvUp(512, 512, 4, 2, 1, True, dtype)\n",
    "        \n",
    "        self.d1 = DeconvDown(512, 512, 4, 2, 1, True, True, dtype)\n",
    "        self.d2 = DeconvDown(512*2, 512, 4, 2, 1, True, True, dtype)\n",
    "        self.d3 = DeconvDown(512*2, 512, 4, 2, 1, True, True, dtype)\n",
    "        self.d4 = DeconvDown(512*2, 512, 4, 2, 1, True, False, dtype)\n",
    "        self.d5 = DeconvDown(512*2, 256, 4, 2, 1, True, False, dtype)\n",
    "        self.d6 = DeconvDown(256*2, 128, 4, 2, 1, True, False, dtype)\n",
    "        self.d7 = DeconvDown(128*2, 64, 4, 2, 1, True, False, dtype)\n",
    "        self.d8 = DeconvDown(64*2, 3, 4, 2, 1, True, False, dtype)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(e1)\n",
    "        e3 = self.e3(e2)\n",
    "        e4 = self.e4(e3)\n",
    "        e5 = self.e5(e4)\n",
    "        e6 = self.e6(e5)\n",
    "        e7 = self.e7(e6)\n",
    "        e8 = self.e8(e7)\n",
    "        \n",
    "        d1 = self.d1(e8, torch.Tensor([]).type(self.dtype))\n",
    "        d2 = self.d2(d1, e7)\n",
    "        d3 = self.d3(d2, e6)\n",
    "        d4 = self.d4(d3, e5)\n",
    "        d5 = self.d5(d4, e4)\n",
    "        d6 = self.d6(d5, e3)\n",
    "        d7 = self.d7(d6, e2)\n",
    "        d8 = self.d8(d7, e1)\n",
    "        \n",
    "        return d8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dtype):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv1 128x128\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # Conv2 64x64\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # Conv3 32x32\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # Conv4 16x16\n",
    "            nn.Conv2d(256, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # Conv5 8x8\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # Conv6 4x4\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # Conv7 4x4\n",
    "            nn.Conv2d(512, 512, 4, 2, 1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            # Conv8 1x1\n",
    "            nn.Conv2d(512, 1, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        ).type(dtype)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.features(x).squeeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "G = Generator(dtype)\n",
    "D = Discriminator(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistortionDataset(Dataset):\n",
    "    def __init__(self, dis_dir, raw_dir):\n",
    "        self.dis_dir = dis_dir\n",
    "        self.raw_dir = raw_dir\n",
    "        self.dis_files = os.listdir(dis_dir)\n",
    "        self.raw_files = os.listdir(raw_dir)\n",
    "        self.transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = mpimg.imread(self.dis_dir + self.dis_files[index])\n",
    "        y = mpimg.imread(self.raw_dir + self.raw_files[index])\n",
    "        x = self.transform(x)\n",
    "        y = self.transform(y)\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.raw_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DistortionDataset('data/paired_dataset256/images_raw256/', 'data/paired_dataset256/images_dis256/')\n",
    "dataloader = DataLoader(dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 256, 256]) torch.Size([5, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/aitorzip/PyTorch-SRGAN/blob/master/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, G, G_optimizer, D, D_optimizer, dtype):\n",
    "        self.G = G\n",
    "        self.D = D\n",
    "        self.G_optimizer = G_optimizer\n",
    "        self.D_optimizer = D_optimizer\n",
    "        self.vgg19 = Vgg19()\n",
    "        self.dtype = dtype\n",
    "        self.MSE_loss = nn.MSELoss().type(dtype) # Content Criterion\n",
    "        self.BCE_loss = nn.BCELoss().type(dtype) # Adversarial criterion\n",
    "        \n",
    "    def train(self, num_epochs, dataloader):\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Starting epoch %d/%d' %(epoch+1, num_epochs))\n",
    "            self.G.train()\n",
    "            self.D.train()\n",
    "            for dis_x, raw_y in dataloader:\n",
    "                dis_x = Variable(dis_x)\n",
    "                raw_y = Variable(raw_y)\n",
    "                \n",
    "                fake_x = self.G(dis_x)\n",
    "                ### Train Discriminator\n",
    "                for _ in range(10):\n",
    "                    dis_x_result = self.Discriminator(dis_x)\n",
    "                    fake_x_result = self.Discriminator(fake_x)\n",
    "                    dis_x_loss = self.BCE_loss(\n",
    "                        dis_x_result, \n",
    "                        Variable(torch.ones(dis_x_result.size())).type(self.dtype)\n",
    "                    )\n",
    "                    fake_x_loss = self.BCE_loss(\n",
    "                        fake_x_result, \n",
    "                        Variable(torch.zeros(fake_x_result.size())).type(self.dtype)\n",
    "                    )\n",
    "                    D_loss = dis_x_loss + fake_x_result\n",
    "                    self.D.zero_grad()\n",
    "                    D_loss.backward()\n",
    "                    self.D.step()\n",
    "                \n",
    "                ### Train Generator\n",
    "                raw_y_feature = self.vgg19(raw_y)\n",
    "                fake_x_feature = self.vgg19(fake_x)\n",
    "                relu_1_2_loss = self.BCE_loss(\n",
    "                    raw_x_feature.h_relu_1_2,\n",
    "                    fake_x_feature.h_relu_1_2\n",
    "                )\n",
    "                relu_5_2_loss = self.BCE_loss(\n",
    "                    raw_x_feature.h_relu_5_2,\n",
    "                    fake_x_feature.h_relu_5_2\n",
    "                )\n",
    "                G_loss = self.BCE_loss(raw_y, dis_x)\n",
    "                G_total_loss = G_loss + relu_1_2_loss + relu_5_2_loss\n",
    "                self.G.zero_grad()\n",
    "                G_total_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
